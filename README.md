# CEO Digital Twin Based on Earnings Call Transcripts

An LLM-based digital twin of Jamie Dimon (CEO of JPMorgan Chase) trained on 17 years of earnings call transcripts to predict his responses to analyst questions.

## ğŸŒ Interactive Demo Website

- [CEO Digital Twin Demo Website](https://github.com/ashleyyu5801-png/CEO-digital-twin-based-on-earnings-call-website/deployments/github-pages)

## ğŸ“Š Project Overview

This project builds and evaluates an LLM-based digital twin of Jamie Dimon using earnings call transcripts and public financial filings. We investigate whether the model can generate realistic responses to analyst questions and evaluate accuracy across multiple dimensions.

### Key Results

| Metric | Result |
|--------|--------|
| Semantic Similarity | 0.81 (FinBERT) |
| Tone Alignment | 0.45-0.52 |
| Training Data | 2,115 Q&A pairs |
| Test Data | 43 Q&A pairs (2025 Q1-Q3) |
| Time Period | July 2007 - October 2024 |

## ğŸ”¬ Methodology

Four specifications were tested:

| Spec | Description | Semantic Sim |
|------|-------------|--------------|
| 1 | Random 500 Q&A pairs | 0.807 |
| 2 | Most Recent 500 Q&A pairs | 0.784 |
| 3 | Recent Q&A + 10-Q Summary | 0.774 |
| **4** | **Persona Summary + 10-Q** | **0.815** |

## ğŸ“ Repository Structure

```
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ index.html                         # Interactive demo website
â”œâ”€â”€ styles.css                         # Website styling
â”œâ”€â”€ script.js                          # Website interactivity
â”‚
â”œâ”€â”€ Code/                              # Development pipeline
â”‚   â”œâ”€â”€ 01_process_test_data.ipynb     # Process SeekingAlpha test transcripts
â”‚   â”œâ”€â”€ 02_summarize_10Q.ipynb         # Summarize 10-Q filings with GPT-4o
â”‚   â”œâ”€â”€ 03_four_specifications.ipynb   # Generate responses (4 specs)
â”‚   â”œâ”€â”€ 04_evaluation.ipynb            # Evaluation (FinBERT, NLI, Tone)
â”‚   â”œâ”€â”€ 05_synthetic_audio.ipynb       # Generate TTS audio
â”‚   â””â”€â”€ 06_generate_tables.ipynb       # Generate LaTeX tables
â”‚
â”œâ”€â”€ Data/                              # Raw input data
â”‚   â”œâ”€â”€ CIQ transcripts/
â”‚   â”‚   â””â”€â”€ 46625H100.csv              # WRDS Capital IQ transcripts (2007-2024)
â”‚   â”œâ”€â”€ SeekingAlpha transcripts 2025/
â”‚   â”‚   â”œâ”€â”€ jpmorgan_chase_2025q1.txt  # Q1 2025 test transcript
â”‚   â”‚   â”œâ”€â”€ jpmorgan_chase_2025q2.txt  # Q2 2025 test transcript
â”‚   â”‚   â””â”€â”€ jpmorgan_chase_2025q3.txt  # Q3 2025 test transcript
â”‚   â”œâ”€â”€ 2025q1.pdf                     # 10-Q filing Q1 2025
â”‚   â”œâ”€â”€ 2025q2.pdf                     # 10-Q filing Q2 2025
â”‚   â””â”€â”€ 2025q3.pdf                     # 10-Q filing Q3 2025
â”‚
â”œâ”€â”€ Processed Data/                    # Intermediate outputs
â”‚   â”œâ”€â”€ 10Q_summaries.json             # GPT-4o summaries of 10-Q filings
â”‚   â”œâ”€â”€ speaker_turns.csv              # Parsed speaker turns from transcripts
â”‚   â””â”€â”€ test_qa_pairs.jsonl            # Extracted test Q&A pairs
â”‚
â””â”€â”€ Results/                           # Final outputs
    â”œâ”€â”€ spec1_random_500_*.json        # Specification 1 results
    â”œâ”€â”€ spec2_recent_500_*.json        # Specification 2 results
    â”œâ”€â”€ spec3_recent_500_plus_10q_*.json  # Specification 3 results
    â”œâ”€â”€ spec4_persona_plus_10q_*.json  # Specification 4 results
    â””â”€â”€ synthetic audio/               # Text-to-speech audio (172 files)
        â”œâ”€â”€ spec1_random_500/          # 43 audio files
        â”œâ”€â”€ spec2_recent_500/          # 43 audio files
        â”œâ”€â”€ spec3_recent_500_plus_10q/ # 43 audio files
        â””â”€â”€ spec4_persona_plus_10q/    # 43 audio files
```

## ğŸš€ Pipeline

1. **Data Collection**: Historical transcripts from WRDS Capital IQ (2007-2024), test transcripts from SeekingAlpha (2025)
2. **Preprocessing**: Extract Q&A pairs where Jamie Dimon responds to analyst questions
3. **10-Q Processing**: Summarize quarterly 10-Q filings using GPT-4o
4. **Response Generation**: Generate synthetic responses using GPT-4o with 4 different prompting strategies
5. **Evaluation**: Measure semantic similarity (FinBERT), informational accuracy (NLI), and tone alignment (Loughran-McDonald)
6. **Audio Synthesis**: Convert generated responses to speech using OpenAI TTS

## ğŸ§ Synthetic Audio

We generated text-to-speech audio for all 43 test responses across 4 specifications (172 total audio files). Listen to samples on the demo website.

## ğŸ‘¥ Research Team

*Author names are listed in alphabetical order by surname.*

- Yufei Chen
- Jiehang Yu
- Karina Zhang

## ğŸ“š Data Sources

- **Training Data**: WRDS Capital IQ Transcripts (JPMorgan Chase earnings calls, 2007-2024)
- **Test Data**: SeekingAlpha (JPMorgan Chase earnings calls, Q1-Q3 2025)
- **Financial Data**: SEC 10-Q filings (Q1-Q3 2025)

## ğŸ”— Links

- [Full Evaluation Results Data (Dropbox)](https://www.dropbox.com/scl/fo/htkfxh4b4779z5r4aa1f4/ALGOhpKNLWzcNSB9M3zuLW0?rlkey=nkkukhf3zs4gt5gfe3td0ttjn&st=07ofqp4j&dl=0)
